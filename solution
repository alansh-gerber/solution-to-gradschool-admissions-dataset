import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import InputLayer, Dense
from sklearn.metrics import mean_squared_error
import sys
import tensorflow as tf
from tensorflow	import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import layers
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.metrics import r2_score

# Load the dataset
dataset = pd.read_csv('/Users/alanshnir/Downloads/regression-challenge/regression-challenge-starter/admissions_data.csv')
# Drop the 'Serial No.' column and assign the new DataFrame back to 'dataset'
dataset = dataset.drop(['Serial No.'], axis=1)

# Separate the labels (target) from the features
labels = dataset['Chance of Admit ']
features = dataset.drop(['Chance of Admit '], axis=1)

# Split the data into training and testing sets
features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=40)

# Standardize the numerical features
numerical_features = features.select_dtypes(include=['float64', 'int64'])
numerical_columns = numerical_features.columns
ct = ColumnTransformer([("only numeric", StandardScaler(), numerical_columns)], remainder='passthrough')
features_train_scaled = ct.fit_transform(features_train)

# Apply the same scaling to the testing data
features_test_scaled = ct.transform(features_test)

# Create the neural network model
model = Sequential()
model.add(InputLayer(input_shape=(features_train_scaled.shape[1],)))
model.add(Dense(64, activation='relu'))
model.add(Dense(1))

# Compile the model with appropriate loss function and optimizer
model.compile(loss='mse', optimizer='adam', metrics=['mae'])  # Include 'mae' metric

# Early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
history = model.fit(features_train_scaled, labels_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])

# Evaluate the model on the test set
loss = model.evaluate(features_test_scaled, labels_test)
print("Test Loss:", loss)

# Make predictions on the test set
predictions = model.predict(features_test_scaled)

# Calculate R-squared (coefficient of determination) to evaluate model performance
r2 = r2_score(labels_test, predictions)
print("R-squared:", r2)

# Ask the user to input their own data
# Instead of using a list, we'll collect the user input in a dictionary
user_data = {}
for col in numerical_columns:
    value = float(input(f"Enter your {col} value: "))
    user_data[col] = [value]

# Create a DataFrame from the user's input
user_df = pd.DataFrame(user_data)

# Transform the user's data using the same fitted ColumnTransformer used for training data
user_data_scaled = ct.transform(user_df)
user_prediction = model.predict(user_data_scaled)[0][0]

print(f"Based on your input data, the predicted chance of grad school acceptance is: {user_prediction:.2f}")

