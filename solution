import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import InputLayer, Dense
from sklearn.metrics import mean_squared_error

import tensorflow as tf
from tensorflow	import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import layers
from sklearn.compose import ColumnTransformer

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
from sklearn.metrics import r2_score

dataset = pd.read_csv('admissions_data.csv')
# Rest of the code...
# Drop the 'Country' column and assign the new DataFrame back to 'dataset'
dataset = dataset.drop(['Serial No.'], axis=1)
batch_sizes_to_test = [8, 16, 32, 64, 128, 256, 512]
#best is 32
# Initialize a dictionary to store the batch size and corresponding MSE scores

# Separate the labels (target) from the features
labels = dataset['Chance of Admit ']
features = dataset.drop(['Chance of Admit '], axis=1)

features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2, random_state=40)
numerical_features = features.select_dtypes(include=['float64', 'int64'])
numerical_columns = numerical_features.columns
ct = ColumnTransformer([("only numeric", StandardScaler(), numerical_columns)], remainder='passthrough')
features_train_scaled = ct.fit_transform(features_train)

# Apply the same scaling to the testing data
features_test_scaled = ct.transform(features_test)
# Create the neural network model
# Create the neural network model
hidden_layer_sizes_to_test = [16, 32, 64, 128]
#best is 64


model = Sequential()

# Add the input layer with the number of features
model.add(layers.InputLayer(input_shape=(features_train_scaled.shape[1],)))

# Add one or more hidden layers
model.add(layers.Dense(64, activation='relu'))

# Add the output layer with 1 neuron (for regression)
model.add(layers.Dense(1))

# Compile the model with appropriate loss function and optimizer
model.compile(loss='mse', optimizer='adam')

# Early stopping to prevent overfitting
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the model
history = model.fit(features_train_scaled, labels_train, epochs=100, batch_size=32, validation_split=0.1, callbacks=[early_stopping])

# Evaluate the model on the test set
loss = model.evaluate(features_test_scaled, labels_test)
print("Test Loss:", loss)

# Make predictions on the test set
predictions = model.predict(features_test_scaled)

# Calculate R-squared (coefficient of determination) to evaluate model performance
r2 = r2_score(labels_test, predictions)
print("R-squared:", r2)

